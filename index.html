<!DOCTYPE html>
<html>
<head>
<style>
div.container {
    width: 100%;
    border: 1px solid gray;
}

header, footer {
    padding: 1em;
    color: white;
    background-color: black;
    clear: left;
    text-align: center;
}

nav {
    float: left;
    max-width: 160px;
    margin: 0;
    padding: 1em;
}

nav ul {
    list-style-type: none;
    padding: 0;
}
   
nav ul a {
    text-decoration: none;
}

article {
    margin-left: 170px;
    border-left: 1px solid gray;
    padding: 1em;
    overflow: hidden;
}
</style>
</head>
<body>

<div class="container">

<header>
   <h1>Deep Learning Reading Group</h1>
</header>
  
<nav>
  <ul>
    <li><a href="#">About</a></li>
    <li><a href="#">Meeting</a></li>
    <li><a href="#">References</a></li>
	<li><a href="#">Video Lectures</a></li>
	<li><a href="#">Code and Datasets</a></li>
	<li><a href="#">Practical Tutorials</a></li>
	<li><a href="#">FAQ</a></li>
  </ul>
</nav>

<article>
  <h1>About</h1>
  <p>The deep learning reading group is organized jointly by <a href="https://bioinf.mpi-inf.mpg.de/homepage/index.php?&account=handl">Lisa Handl</a> and <a href="https://bioinf.mpi-inf.mpg.de/homepage/index.php?&account=adinfo">Azim Dehghani Amirabad</a> . The group meets bi-weekly to discuss topics of interest (basic concepts as well as recent research papers in deep learning). It is open to anyone at Max Planck Institute for Informatics or Saarland University. Interested people with other affiliations are also welcome, but are requested to contact us.</p>
  <h1>Meetings</h1>
	<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;border-color:#999;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#999;color:#444;background-color:#F7FDFA;border-top-width:1px;border-bottom-width:1px;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#999;color:#fff;background-color:#26ADE4;border-top-width:1px;border-bottom-width:1px;}
.tg .tg-qntn{font-family:Arial, cursive, sans-serif !important;;background-color:#34cdf9;vertical-align:top}
.tg .tg-l60n{font-family:Arial, cursive, sans-serif !important;;vertical-align:top}
.tg .tg-yw4l{vertical-align:top}
</style>
<table class="tg">
  <tr>
    <th class="tg-qntn"></th>
    <th class="tg-qntn">Date</th>
    <th class="tg-qntn">Topics</th>
    <th class="tg-qntn">Speaker</th>
    <th class="tg-qntn">Refrences</th>
    <th class="tg-qntn">Slides</th>
  </tr>
  <tr>
    <td class="tg-l60n">0.</td>
    <td class="tg-l60n">17/02/2017</td>
    <td class="tg-l60n">Kick-off meeting</td>
    <td class="tg-l60n">Azim</td>
    <td class="tg-l60n">-</td>
    <td class="tg-l60n"><a href="https://github.com/CSBioAzim/DeepLearninggroup/blob/master/Deep_learning_reading_group.pdf">Organization</a></td>
  </tr>
  <tr>
    <td class="tg-l60n">1.</td>
    <td class="tg-l60n">May 11, 2017 (2:30-4:00 pm)</td>
    <td class="tg-l60n">Feedforward neural networks
	    <ul>
		    <li>Basic concept</li>
		    <li>Universality theorem</li>
		    <li>Backpropagation / gradient descent</li>
		    <li>Regularization ideas <br>
		    	(weight decay, early stopping, dropout, ...)</li>
	    </ul>
    </td>
    <td class="tg-l60n">Lisa</td>
    <td class="tg-l60n">[1] Parts of Chapters 1-4 <br>
	  		[2] Parts of Chapter 6</td>
    <td class="tg-l60n"><a href="https://github.com/CSBioAzim/DeepLearninggroup/blob/master/2017_05_11_FeedforwardNNs_Lisa.pdf">FeedforwardNNs</a></td>
  </tr>
  <tr>
    <td class="tg-l60n">2.</td>
    <td class="tg-l60n">May 30, 2017 (3:00-4:30 pm)</td>
    <td class="tg-l60n">Deep convolutional neural nets
	    <ul>
		    <li>Why do we want to train deep nets?</li>
		    <li>Why are deep nets hard to train? <br>
			    (e.g., unstable gradient problem)</li>
		    <li>Idea of convolutional neural nets<br>
			    (local receptive fields, weight sharing, pooling)</li>
		    
		    <li>Types of convolutional neural nets<br>
			    (pooling, inception, 1 * 1 convolution)</li>
		    <li>Application to MNIST dataset <br>
			    (with different architectures)</li>
	    </ul>
    </td>
    <td class="tg-l60n">Azim</td>
    <td class="tg-l60n">[1] Chapters 5 and 6</td>
    <td class="tg-l60n"><a href="https://github.com/CSBioAzim/DeepLearninggroup/blob/master/CNN.pdf">CNN</a></td>
  </tr>
  <tr>
    <td class="tg-l60n">3.</td>
    <td class="tg-l60n">June 1, 2017 (3:00-4:30 pm)</td>
    <td class="tg-l60n">Recurrent neural nets (I)
	    <ul>
		    <li>Graphical representation (circuit vs. unfolded)</li>
		    <li>Backpropagation through time</li>
		    <li>Teacher forcing</li>
		    <li>Interpretation as directed graphical models</li>
		    <li>Modeling sequences conditioned on context</li>
		    <li>Bidirectional recurrent neural nets</li>
		    <li>Sequence-to-sequence architectures</li>
	    </ul>    
    </td>
    <td class="tg-l60n">Michael</td>
    <td class="tg-l60n">[2] Sections 10.1 to 10.4</td>
    <td class="tg-l60n"><a href="https://github.com/CSBioAzim/DeepLearninggroup/blob/master/2017_06_01_RecurrentNNs_Michael.pdf">RNNs_1</a></td>
  </tr>
  <tr>
    <td class="tg-l60n">4.</td>
    <td class="tg-l60n">June 13, 2017 (3:00-4:30 pm)</td>
    <td class="tg-l60n">Recurrent neural nets (II)
	    <ul>
		    <li>Deep recurrent neural nets</li>
		    <li>The challenge of long-term dependencies<br>
		    	(variation of the unstable gradient problem)</li>
		    <li>Leaky Units and Other Strategies for Multiple
Time Scales</li>
		    <li>LSTM</li>
	    </ul>
    </td>
    <td class="tg-l60n">Mittul</td>
    <td class="tg-l60n">Sections 10.5 to 10.10 <br>
	  (except 10.8)</td>
    <td class="tg-l60n"><a href="https://github.com/CSBioAzim/DeepLearninggroup/blob/master/seq_modelling.pdf">RNNs_2</a></td>
  </tr>
  <tr>
    <td class="tg-l60n">5.</td>
    <td class="tg-l60n">July 4, 2017 (3:00-4:30 pm)</td>
    <td class="tg-l60n">Practical methodology
	    <ul>
		    <li>Hyperparameters, model capacity and caveats</li>
		    <li>Hyperparameters selection methods <br>
			(manual, grid search, random search, Bayesian optimization)</li>
		    <li>Model debugging strategies</li>
	    </ul>
</td>
    <td class="tg-l60n">Sivarajan</td>
    <td class="tg-l60n">[1] Chapter 3 (last third) <br>
	    + [2] Chapter 11</td>
    <td class="tg-l60n"><a href="https://github.com/CSBioAzim/DeepLearninggroup/blob/master/04072017_DLRG_PracticalMethodology.pdf">PracticalMethodology</a></td>
  </tr>
  <tr>
    <td class="tg-l60n">6.</td>
    <td class="tg-l60n">August 3, 2017 (3:00-4:30 pm)</td>
    <td class="tg-l60n">Software session
	    <ul>
		  <li>Short overview over existing packages<br>
		    (Caffe, Theano, Torch7, TensorFlow, Keras)</li>
		  <li>Tutorial of one package (Keras)</li>
		  <li>Provide code examples with which people <br>
			  can play around</li>
	    </ul>
	</td>
    <td class="tg-l60n">Sarvesh</td>
    <td class="tg-l60n"></td>
    <td class="tg-l60n"><a href="https://github.com/CSBioAzim/DeepLearninggroup/blob/master/DLRG-software-session.ipynb">JupyterNotebook</a></td>
  </tr>
<tr>
    <td class="tg-l60n">7.</td>
    <td class="tg-l60n">August 17, 2017 (3:00-4:30 pm)</td>
    <td class="tg-l60n">DeepCpG: accurate prediction of single-cell DNA methylation<br>
	    		states using deep learning</td>
    <td class="tg-l60n">Fabian</td>
	<td class="tg-l60n"><a href="http://doi.org/10.1186/s13059-017-1189-z">Paper</a></td>
    <td class="tg-l60n"></td>
  </tr>
<tr>
    <td class="tg-l60n">8.</td>
    <td class="tg-l60n">August 31, 2017 (3:00-4:30 pm)</td>
    <td class="tg-l60n">Leveraging uncertainty information from deep neural networks<br>
	    		for disease detection</td>
    <td class="tg-l60n">Lisa</td>
	<td class="tg-l60n"><a href="http://www.biorxiv.org/content/early/2017/08/02/084210">Paper</a></td>
    <td class="tg-l60n"></td>
  </tr>
<tr>
    <td class="tg-l60n">9.</td>
    <td class="tg-l60n">September 14, 2017 (3:00-4:30 pm)</td>
    <td class="tg-l60n">tba</td>
    <td class="tg-l60n">tba</td>
	<td class="tg-l60n"></td>
    <td class="tg-l60n"></td>
  </tr>
</table>
<br>We also have a <a href="https://calendar.google.com/calendar/embed?src=7vo4d1qcj39vvn76fdv4p4evl0%40group.calendar.google.com&ctz=Europe/Berlin
	">Google calender</a> which we will keep up to date with all sessions.<br>

<h1> Topics </h1>
<ul>
	<li>Introduction to Neural Nets</li>
	<li>Reccurent Net</li>
	<li>Deep Convolutional Net</li>
	<li>Deep Belief Net</li>
	<li>Restricted Boltzmann Machines</li>
	<li>Deep Autoencoder</li>
	<li>Deep Attention Network</li>
	<li>Deep Transfer Learning </li>
	<li>Deep Reinforcement Learning</li>
	<li>Deep Generative Model</li>
	<li>Optimization for Deep Learning</li>
	<li>GPU Programming</li>
	<li>Visualizing and Interpreting Deep Neural Nets </li>
	<li>Platforms and Libraries </li>
</ul> 
<h1> Discussion </h1>
	<p> Start a new discussion<a href="https://github.com/CSBioAzim/DeepLearninggroup/issues/new"> here</a></p>
<h1> References  </h1>
 
<p> [1] <a href="http://neuralnetworksanddeeplearning.com/index.html">Neural Networks and Deep Learning</a> (Michael Nielsen)  </p>
<p> [2] <a href="http://www.deeplearningbook.org/">Deep Learning</a> (Ian Goodfellow, Yoshua Bengio and Aaron Courville)  </p>
	
 <h1> Video Lectures </h1>
   <p> <a href="http://videolectures.net/deeplearning2016_montreal/">Deep Learning Summer School, 2016</a>   </p>

  <p> <a href="http://videolectures.net/jul09_hinton_deeplearn/">Geoffrey E. Hinton</a>   </p>
 
 <h1> Code and Datasets</h1>
	<p> <a href="https://github.com/mnielsen/neural-networks-and-deep-learning">GitHub repository for the book Neural Networks and Deep Learning</a></p>
	
 <h1> Practical Tutorials</h1>
 <p> Coming soon!</p>

 <h1>Softwares</h1>
 <ul>
	<li>Caffe</li>
	<li>Torch</li>
	 <li>Theano</li>
	 <li>Cuda-convent</li>
	 <li>Keras</li>
	  <li>Chained</li>
	  <li>Minpy</li>
	 <li>CUTorch</li>
	 <li>D4j</li>
	  <li>Paddle</li>
	 
	
</ul> 
	
 <h1>Collections of Papers</h1>
 <p><a href="https://github.com/HFTrader/DeepLearningBook/blob/master/DeepLearningPapers.md">
Deep learning papers in general</a></p>
  <p><a href="https://github.com/gokceneraslan/awesome-deepbio">
Deep learning applications in computational biology
</a></p>
<!--
 <h1>FAQ</h1>
 
<ul>
  <li>Why has deep learning suddenly become so popular? ?</li>
  <li>How should I choose right Deep Net for my problem?</li>	
  <li>How should I run my Deep Net on GPU?</li>	
</ul>
-->
 </article>

</div>

</body>
</html>
